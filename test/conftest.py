# test/conftest.py
from __future__ import annotations

import os
import pathlib
import uuid
from typing import Generator, Optional

import pytest

from test.helpers.reporter import Reporter


def _get_or_create_run_id(cfg: pytest.Config) -> str:
    """Return a stable run_id for the entire pytest invocation.

    A single pytest invocation should write to a single jsonl file. If run_id is
    generated in more than one place (e.g., hooks + fixtures), you'll end up with
    multiple output files for what you think is "one run".
    """
    run_id = getattr(cfg, "_e27_run_id", None)
    if not run_id:
        run_id = uuid.uuid4().hex
        setattr(cfg, "_e27_run_id", run_id)
    return run_id


def _get_or_create_report_path(cfg: pytest.Config) -> pathlib.Path:
    """Return the jsonl path for this pytest invocation (stable)."""
    p = getattr(cfg, "_e27_report_path", None)
    if p is None:
        base_dir = pathlib.Path(cfg.getoption("--e27-artifacts-dir"))
#        artifacts_dir = base_dir / "test_runs"
        artifacts_dir = base_dir
        artifacts_dir.mkdir(parents=True, exist_ok=True)
        p = artifacts_dir / f"{_get_or_create_run_id(cfg)}.jsonl"
        setattr(cfg, "_e27_report_path", p)
    return p


def pytest_configure(config: pytest.Config) -> None:
    """Initialize run_id/report path early so hooks/fixtures share them."""
    _get_or_create_report_path(config)


def pytest_addoption(parser: pytest.Parser) -> None:
    group = parser.getgroup("e27")
    group.addoption(
        "--e27-live",
        action="store_true",
        default=False,
        help="Enable tests marked as live (requires real panel + credentials).",
    )
    group.addoption(
        "--e27-report",
        action="store",
        default=os.getenv("ELK_E27_REPORT_FORMAT", "jsonl"),
        choices=("jsonl", "yaml", "both", "none"),
        help="Test artifact format: jsonl (default), yaml, both, or none. "
             "YAML is derived from JSON records.",
    )
    group.addoption(
        "--e27-artifacts-dir",
        action="store",
        default=os.getenv("ELK_E27_ARTIFACTS_DIR", "artifacts/test_runs"),
        help="Directory to write E27 test artifacts (default: artifacts/test_runs).",
    )


@pytest.hookimpl(hookwrapper=True, tryfirst=True)
def pytest_runtest_makereport(item: pytest.Item, call: pytest.CallInfo):
    # Attach the report to the item so hooks/fixtures can access pass/fail and exceptions.
    outcome = yield
    rep = outcome.get_result()
    setattr(item, f"rep_{rep.when}", rep)
    if rep.when == "teardown" and rep.failed:
        mark = item.get_closest_marker("xfail")
        if mark is not None:
            reason = mark.kwargs.get("reason")
            if reason is None and mark.args:
                reason = str(mark.args[0])
            if reason and "teardown" in str(reason).lower():
                rep.outcome = "skipped"
                rep.wasxfail = reason

@pytest.fixture
def notifier():
    from elkm1_lib.notify import Notifier
    return Notifier()

@pytest.fixture()
def fail_teardown(request):
    def fin():
        pytest.fail("intentional teardown failure", pytrace=True)
    request.addfinalizer(fin)
    yield

@pytest.fixture(scope="session")
def e27_run_id(request: pytest.FixtureRequest) -> str:
    # Stable per pytest invocation (shared with hooks).
    return _get_or_create_run_id(request.config)


@pytest.fixture()
def reporter(request: pytest.FixtureRequest, e27_run_id: str) -> Generator[Reporter, None, None]:
    """
    Create a per-test Reporter and attach it to the item.
    We do NOT finalize here; finalization happens in pytest_runtest_teardown,
    after rep_teardown has been generated by pytest.
    """
    cfg = request.config
    report_mode = str(cfg.getoption("--e27-report")).lower()
    artifacts_dir = pathlib.Path(str(cfg.getoption("--e27-artifacts-dir")))
    emit_jsonl = report_mode in ("jsonl", "both")
    emit_yaml = report_mode in ("yaml", "both")
    enable = report_mode != "none"

    r = Reporter(
        run_id=e27_run_id,
        test_id=request.node.nodeid,
        artifacts_dir=artifacts_dir,
        emit_jsonl=emit_jsonl,
        emit_yaml=emit_yaml,
        enable=enable,
    )
    r.test_start()

    # Make it accessible to hooks
    request.node._e27_reporter = r  # type: ignore[attr-defined]

    yield r


def _finalize_reporter_for_item(item: pytest.Item) -> None:
    r: Optional[Reporter] = getattr(item, "_e27_reporter", None)  # type: ignore[attr-defined]
    if r is None:
        return

    rep_setup = getattr(item, "rep_setup", None)
    rep_call = getattr(item, "rep_call", None)
    rep_teardown = getattr(item, "rep_teardown", None)

    outcome = "unknown"
    longrepr = None
    when = None

    # Setup failures always win
    if rep_setup is not None and rep_setup.failed:
        outcome = "fail"
        longrepr = rep_setup.longrepr
        when = "setup"

    # Call phase
    elif rep_call is not None:
        when = "call"
        if rep_call.passed:
            outcome = "pass"
        elif rep_call.skipped:
            outcome = "skip"
            longrepr = rep_call.longrepr
        else:
            outcome = "fail"
            longrepr = rep_call.longrepr

    # Teardown failures override a pass
    if outcome == "pass" and rep_teardown is not None and rep_teardown.failed:
        outcome = "fail"
        longrepr = rep_teardown.longrepr
        when = "teardown"

    r.test_end(outcome=outcome, when=when, longrepr=longrepr)
    r.finalize()

    # Prevent double-finalization if pytest calls teardown hooks unusually
    try:
        delattr(item, "_e27_reporter")  # type: ignore[attr-defined]
    except Exception:
        pass


def pytest_runtest_teardown(item: pytest.Item, nextitem) -> None:
    """
    Finalize after teardown completes and rep_teardown is available.
    This is the key change for reliable teardown failure reporting.
    """
    _finalize_reporter_for_item(item)


def pytest_runtest_setup(item: pytest.Item) -> None:
    """
    If setup itself fails before the test body can request the reporter fixture,
    we still want the reporter to exist and capture the failure.
    So: create a reporter eagerly if reporting is enabled.
    """
    cfg = item.config
    report_mode = str(cfg.getoption("--e27-report")).lower()
    if report_mode == "none":
        return

    if hasattr(item, "_e27_reporter"):
        return

    run_id = getattr(cfg, "_e27_run_id", None)
    if run_id is None:
        run_id = uuid.uuid4().hex
        cfg._e27_run_id = run_id  # type: ignore[attr-defined]

    artifacts_dir = pathlib.Path(str(cfg.getoption("--e27-artifacts-dir")))
    emit_jsonl = report_mode in ("jsonl", "both")
    emit_yaml = report_mode in ("yaml", "both")

    r = Reporter(
        run_id=run_id,
        test_id=item.nodeid,
        artifacts_dir=artifacts_dir,
        emit_jsonl=emit_jsonl,
        emit_yaml=emit_yaml,
        enable=True,
    )
    r.test_start()
    item._e27_reporter = r  # type: ignore[attr-defined]


@pytest.fixture()
def fail_setup():
    assert False, "intentional setup failure"


@pytest.fixture()
def fail_teardown():
    yield
    assert False, "intentional teardown failure"
